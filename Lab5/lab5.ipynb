{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  class\n",
      "0      Film, który zbyt długo się ciągnie. Słabni...      1\n",
      "1  Pozytywne zaskoczenie. Bardzo dobrze zrealizow...      0\n",
      "2  Kapitalne efekty wizualne. Widać, że ekipa pra...      0\n",
      "3  Niezwykła chemia między postaciami. To, co ich...      0\n",
      "4      Brak zaskakujących momentów. Cała fabuła j...      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read File Data\n",
    "with open('positive.txt', 'r', encoding='utf-8') as file:\n",
    "    positive_data = file.readlines()\n",
    "\n",
    "with open('negative.txt', 'r', encoding='utf-8') as file:\n",
    "    negative_data = file.readlines()\n",
    "\n",
    "# Create dataframe with class (0 - positive, 1 - negative)\n",
    "df_positive = pd.DataFrame({'text': positive_data, 'class': 0})\n",
    "df_negative = pd.DataFrame({'text': negative_data, 'class': 1})\n",
    "\n",
    "# Connect positive and negative dataframes\n",
    "df = pd.concat([df_positive, df_negative], ignore_index=True)\n",
    "\n",
    "# Shuffle dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Zaimportuj wszystkie potrzebne biblioteki\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Podziel dane na zbiór treningowy i testowy\n",
    "# (Ważne!!! Zbioru testowego nie można zmieniać w trakcie). \n",
    "# Zbiór testowy będzie złożony z 20% całości danych (test_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['class'], \n",
    "test_size=0.2, random_state=42) \n",
    "\n",
    "# 3. Utwórz pipeline klasyfikatorów\n",
    "classifiers = [ \n",
    "    ('Decision Tree', DecisionTreeClassifier()), \n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, \n",
    "random_state=42)), \n",
    "    ('SVM', SVC()) \n",
    "]\n",
    "\n",
    "vectorizers = [\n",
    "    ('Words with at least 3 letters', CountVectorizer(token_pattern=r'\\b\\w{3,}\\b')),\n",
    "    ('Words with 3-8 letters', CountVectorizer(token_pattern=r'\\b\\w{3,8}\\b')),\n",
    "    ('Words with 3-10 letters', CountVectorizer(token_pattern=r'\\b\\w{3,10}\\b')),\n",
    "    ('Words with 3-12 letters', CountVectorizer(token_pattern=r'\\b\\w{3,12}\\b')),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Decision Tree\n",
      "Vectorizer: Words with at least 3 letters\n",
      "Cross-Validation Scores: [0.73333333 0.5        0.76666667 0.89655172 0.79310345]\n",
      "Mean CV Accuracy: 0.7379\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        24\n",
      "           1       0.69      0.69      0.69        13\n",
      "\n",
      "    accuracy                           0.78        37\n",
      "   macro avg       0.76      0.76      0.76        37\n",
      "weighted avg       0.78      0.78      0.78        37\n",
      "\n",
      "================================================== \n",
      "\n",
      "Classifier: Decision Tree\n",
      "Vectorizer: Words with 3-4 letters\n",
      "Cross-Validation Scores: [0.73333333 0.56666667 0.76666667 0.86206897 0.79310345]\n",
      "Mean CV Accuracy: 0.7444\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77        24\n",
      "           1       0.56      0.38      0.45        13\n",
      "\n",
      "    accuracy                           0.68        37\n",
      "   macro avg       0.63      0.61      0.61        37\n",
      "weighted avg       0.66      0.68      0.66        37\n",
      "\n",
      "================================================== \n",
      "\n",
      "Classifier: Decision Tree\n",
      "Vectorizer: Words with 3-6 letters\n",
      "Cross-Validation Scores: [0.7        0.73333333 0.66666667 0.72413793 0.82758621]\n",
      "Mean CV Accuracy: 0.7303\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77        24\n",
      "           1       0.59      0.77      0.67        13\n",
      "\n",
      "    accuracy                           0.73        37\n",
      "   macro avg       0.72      0.74      0.72        37\n",
      "weighted avg       0.76      0.73      0.74        37\n",
      "\n",
      "================================================== \n",
      "\n",
      "Classifier: Decision Tree\n",
      "Vectorizer: Words with 3-8 letters\n",
      "Cross-Validation Scores: [0.76666667 0.56666667 0.76666667 0.89655172 0.82758621]\n",
      "Mean CV Accuracy: 0.7648\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73        24\n",
      "           1       0.50      0.46      0.48        13\n",
      "\n",
      "    accuracy                           0.65        37\n",
      "   macro avg       0.61      0.61      0.61        37\n",
      "weighted avg       0.64      0.65      0.65        37\n",
      "\n",
      "================================================== \n",
      "\n",
      "Classifier: Random Forest\n",
      "Vectorizer: Words with at least 3 letters\n",
      "Cross-Validation Scores: [0.63333333 0.63333333 0.7        0.65517241 0.75862069]\n",
      "Mean CV Accuracy: 0.6761\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.42      0.56        24\n",
      "           1       0.44      0.85      0.58        13\n",
      "\n",
      "    accuracy                           0.57        37\n",
      "   macro avg       0.64      0.63      0.57        37\n",
      "weighted avg       0.70      0.57      0.56        37\n",
      "\n",
      "================================================== \n",
      "\n",
      "Classifier: Random Forest\n",
      "Vectorizer: Words with 3-4 letters\n",
      "Cross-Validation Scores: [0.73333333 0.56666667 0.76666667 0.82758621 0.82758621]\n",
      "Mean CV Accuracy: 0.7444\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78        24\n",
      "           1       0.60      0.46      0.52        13\n",
      "\n",
      "    accuracy                           0.70        37\n",
      "   macro avg       0.67      0.65      0.65        37\n",
      "weighted avg       0.69      0.70      0.69        37\n",
      "\n",
      "================================================== \n",
      "\n",
      "Classifier: Random Forest\n",
      "Vectorizer: Words with 3-6 letters\n",
      "Cross-Validation Scores: [0.7        0.8        0.73333333 0.65517241 0.93103448]\n",
      "Mean CV Accuracy: 0.7639\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85        24\n",
      "           1       0.71      0.77      0.74        13\n",
      "\n",
      "    accuracy                           0.81        37\n",
      "   macro avg       0.79      0.80      0.80        37\n",
      "weighted avg       0.82      0.81      0.81        37\n",
      "\n",
      "================================================== \n",
      "\n",
      "Classifier: Random Forest\n",
      "Vectorizer: Words with 3-8 letters\n",
      "Cross-Validation Scores: [0.63333333 0.66666667 0.73333333 0.68965517 0.86206897]\n",
      "Mean CV Accuracy: 0.7170\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77        24\n",
      "           1       0.59      0.77      0.67        13\n",
      "\n",
      "    accuracy                           0.73        37\n",
      "   macro avg       0.72      0.74      0.72        37\n",
      "weighted avg       0.76      0.73      0.74        37\n",
      "\n",
      "================================================== \n",
      "\n",
      "Classifier: SVM\n",
      "Vectorizer: Words with at least 3 letters\n",
      "Cross-Validation Scores: [0.7        0.63333333 0.76666667 0.75862069 0.86206897]\n",
      "Mean CV Accuracy: 0.7441\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.70        24\n",
      "           1       0.50      0.69      0.58        13\n",
      "\n",
      "    accuracy                           0.65        37\n",
      "   macro avg       0.64      0.66      0.64        37\n",
      "weighted avg       0.69      0.65      0.66        37\n",
      "\n",
      "================================================== \n",
      "\n",
      "Classifier: SVM\n",
      "Vectorizer: Words with 3-4 letters\n",
      "Cross-Validation Scores: [0.76666667 0.6        0.73333333 0.86206897 0.79310345]\n",
      "Mean CV Accuracy: 0.7510\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        24\n",
      "           1       0.42      0.38      0.40        13\n",
      "\n",
      "    accuracy                           0.59        37\n",
      "   macro avg       0.55      0.55      0.55        37\n",
      "weighted avg       0.59      0.59      0.59        37\n",
      "\n",
      "================================================== \n",
      "\n",
      "Classifier: SVM\n",
      "Vectorizer: Words with 3-6 letters\n",
      "Cross-Validation Scores: [0.73333333 0.6        0.73333333 0.75862069 0.86206897]\n",
      "Mean CV Accuracy: 0.7375\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76        24\n",
      "           1       0.55      0.46      0.50        13\n",
      "\n",
      "    accuracy                           0.68        37\n",
      "   macro avg       0.64      0.63      0.63        37\n",
      "weighted avg       0.67      0.68      0.67        37\n",
      "\n",
      "================================================== \n",
      "\n",
      "Classifier: SVM\n",
      "Vectorizer: Words with 3-8 letters\n",
      "Cross-Validation Scores: [0.73333333 0.6        0.76666667 0.89655172 0.82758621]\n",
      "Mean CV Accuracy: 0.7648\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71        24\n",
      "           1       0.46      0.46      0.46        13\n",
      "\n",
      "    accuracy                           0.62        37\n",
      "   macro avg       0.58      0.58      0.58        37\n",
      "weighted avg       0.62      0.62      0.62        37\n",
      "\n",
      "================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Utwórz pętlę która przetestuje wszystkie klasyfikatory\n",
    "results = [] \n",
    " \n",
    "for classifier_name, classifier in classifiers: \n",
    "    for vectorizer_name, vectorizer in vectorizers:\n",
    "        # Utwórz pipeline z CountVectorizer i klasyfikatorem \n",
    "        pipeline = Pipeline([ \n",
    "            ('vectorizer', vectorizer), \n",
    "            ('classifier', classifier) \n",
    "        ]) \n",
    "\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy') \n",
    "    \n",
    "        # Trenuj model \n",
    "        pipeline.fit(X_train, y_train) \n",
    "\n",
    "        # Przewiduj na danych testowych \n",
    "        y_pred = pipeline.predict(X_test) \n",
    "\n",
    "        # Oceniaj wyniki \n",
    "        accuracy = accuracy_score(y_test, y_pred) \n",
    "        report = classification_report(y_test, y_pred) \n",
    "\n",
    "        # Dodaj wyniki do listy \n",
    "        results.append({ \n",
    "            'Classifier': classifier_name, \n",
    "            'Vectorizer': vectorizer_name,\n",
    "            'Mean Accuracy': cv_scores.mean(), \n",
    "            'Cross-Validation Scores': cv_scores, \n",
    "            'Classification Report': report \n",
    "        })\n",
    "\n",
    "# 5. Wyświetl wyniki\n",
    "best_methods = []\n",
    "\n",
    "for result in results: \n",
    "    best_methods.append((result['Mean Accuracy'], f\"{result['Classifier']}\", f\"{result['Vectorizer']}\"))\n",
    "    print(f\"Classifier: {result['Classifier']}\") \n",
    "    print(f\"Vectorizer: {result['Vectorizer']}\")\n",
    "    print(f\"Cross-Validation Scores: {result['Cross-Validation Scores']}\") \n",
    "    print(f\"Mean CV Accuracy: {result['Mean Accuracy']:.4f}\") \n",
    "    print(\"Classification Report:\") \n",
    "    print(result['Classification Report']) \n",
    "    print(\"=\" * 50, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST ALGORITHMS\n",
      "\n",
      "0.7648 - Decision Tree + Words with 3-8 letters\n",
      "0.7648 - SVM + Words with 3-8 letters\n",
      "0.7639 - Random Forest + Words with 3-6 letters\n",
      "0.7510 - SVM + Words with 3-4 letters\n",
      "0.7444 - Decision Tree + Words with 3-4 letters\n",
      "0.7444 - Random Forest + Words with 3-4 letters\n",
      "0.7441 - SVM + Words with at least 3 letters\n",
      "0.7379 - Decision Tree + Words with at least 3 letters\n",
      "0.7375 - SVM + Words with 3-6 letters\n",
      "0.7303 - Decision Tree + Words with 3-6 letters\n",
      "0.7170 - Random Forest + Words with 3-8 letters\n",
      "0.6761 - Random Forest + Words with at least 3 letters\n"
     ]
    }
   ],
   "source": [
    "# Zastanów się który algorytm działa najlepiej! \n",
    "best_methods = sorted(best_methods, key = lambda x : x[0], reverse=True)\n",
    "\n",
    "print('BEST ALGORITHMS')\n",
    "print()\n",
    "for best in best_methods:\n",
    "    print(f\"{best[0]:.4f} - {best[1]} + {best[2]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envGlobal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
